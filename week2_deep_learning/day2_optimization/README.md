# Day 2: 深度网络优化

## 学习目标
掌握深度神经网络的优化技术和正则化方法

## 详细内容

### 1. 优化器进阶
```python
01_optimizers.py
```
- SGD/Momentum
- Adam/AdamW
- RMSprop
- 学习率调度

### 2. 正则化技术
```python
02_regularization.py
```
- Dropout实现
- L1/L2正则化
- Early Stopping
- 权重衰减

### 3. 批量归一化
```python
03_batch_norm.py
```
- BatchNorm原理
- LayerNorm
- InstanceNorm
- GroupNorm

### 4. 损失函数
```python
04_loss_functions.py
```
- 分类损失
- 回归损失
- 自定义损失
- 多任务损失

### 5. 训练技巧
```python
05_training_tricks.py
```
- 梯度裁剪
- 学习率预热
- 模型集成
- 交叉验证

## 实践项目
1. 深度网络优化
   - 基线模型
   - 优化策略
   - 性能提升

2. 模型正则化
   - 过拟合处理
   - 验证集评估
   - 最佳实践

## 作业
1. 实现多种优化器
2. 对比正则化方法
3. 优化训练流程

## 参考资源
- 优化算法论文
- PyTorch优化器文档
- 深度学习最佳实践
